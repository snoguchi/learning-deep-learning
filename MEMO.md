# ゼロから作るDeep Learning

## python
- numpyのoperator overloadが気持ち悪い。慣れると少ない記述で行列演算できて便利そう

## ch02
- パーセプトロンで論理回路
  - 単層パーセプトロンでANDやORなどの論理回路を表現できる
  - 単層パーセプトロンではXORは表現できない
  - 2層のパーセプトロンではXORを表現できる
- 単層 vs 多層
  - 単層のパーセプトロン = 線形領域しか表現できない
  - 多層のパーセプトロン = 非線形領域を表現できる

## ch03
- 活性化関数
  - ノードに入力された入力信号の総和を出力信号に変換する関数
    - ステップ関数（線形）
    - シグモイド関数（非線形）
    - ReLU関数（非線形）
  - 多層パーセプトロン＝ニューラルネットでは、活性化関数は非線形でないと意味がない
    - 線形関数だと多層は一層にまとめられちゃって隠れ層の意味がなくなるから
- 多次元配列演算
  - ニューラルネットの計算（入力信号から出力信号を算出する）を効率的に実行するために必要
- 出力層
  - 出力層の特別な活性化関数
    - 回帰問題 → 恒等関数
    - 分類問題 → ソフトマックス関数（出力値の総和に対する割合、出力が確率になる）
- バッチ処理
  - 入力信号を「束」にまとめる
  - コンピュータで計算するときの効率にメリットがある（ライブラリの最適化など）